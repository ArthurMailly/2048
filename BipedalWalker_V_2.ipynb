{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BipedalWalker V-2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurMailly/2048/blob/main/BipedalWalker_V_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kJlFUlcrQk-3"
      },
      "cell_type": "markdown",
      "source": [
        "## TO GET STATRTED WITH BIPEDAL WALKER TUTORIAL,FIRST OF ALL LETS GET INTO HOW IT WORKS\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jH_lEwH0RK8O"
      },
      "cell_type": "markdown",
      "source": [
        "#First of all install the certain dependencies that you will require while working in google Colab\n",
        "\n",
        "## There is a rendering problem in Colab as it runs in web browser so the *env.render()* will not work rather it will give you lots of error so we will by pass that error by storing our results in a video and after applying ARS, we will download it."
      ]
    },
    {
      "metadata": {
        "id": "H18Dq-YjR7k7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd6eaa4-dadf-4f15-f4e8-696855ce10dc"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym\n",
        "!apt-get update\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "!apt-get install xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "!pip -q install pyglet\n",
        "!pip -q install pyopengl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,608 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,457 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,424 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,275 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,700 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,164 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Fetched 22.5 MB in 4s (5,016 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m941.1/941.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ele16OgySLjR"
      },
      "cell_type": "markdown",
      "source": [
        "**BOX2D Let you use the bipedal agent and environment**\n",
        "\n",
        "**Pybullet is you key to physical simulations and a good alternative to MOJOCO which can cost you.**"
      ]
    },
    {
      "metadata": {
        "id": "Eok_4dD9mFE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9df5f6-e504-4d7a-8f9e-77b39e57f49b"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install swig\n",
        "!pip install box2d box2d-kengz\n",
        "!pip install pybullet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (811 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 124645 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.2.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting box2d-kengz\n",
            "  Downloading Box2D-kengz-2.3.3.tar.gz (425 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.4/425.4 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d, box2d-kengz\n",
            "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2367284 sha256=6c4cf216d80200677048dc5642f0b3112c9db016435750d229234963637e7178\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp310-cp310-linux_x86_64.whl size=2367313 sha256=570c52f6c643efd2177b34a27a34620270ce01fc756d494ac3b105d7bb91605b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a3/5f/6396406aa0163da86c2a8d28304a120b55cfa98363654d853b\n",
            "Successfully built box2d box2d-kengz\n",
            "Installing collected packages: box2d-kengz, box2d\n",
            "Successfully installed box2d-2.3.2 box2d-kengz-2.3.3\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8KjX9UtlSWKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "bfb5cdff-90ec-40b1-f0da-4a006e2fb0e3"
      },
      "cell_type": "code",
      "source": [
        "# Start virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "import os\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" #+ str(display.screen)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Display' object has no attribute 'screen'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9c1543332c7c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISPLAY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Display' object has no attribute 'screen'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Q9UYPMYakrpL"
      },
      "cell_type": "markdown",
      "source": [
        "# Augmented Random Search"
      ]
    },
    {
      "metadata": {
        "id": "Gr6qsIHCTBmz"
      },
      "cell_type": "markdown",
      "source": [
        "## Augmented Random Search(ARS) is actually up to 15 TIMES FASTER than other algorithms with higher rewards in specific applications! That’s insane!\n",
        "### One of the ways, ARS is able to be so much faster is that unlike a lot of reinforcement learning algorithms that use deep learning with many hidden layers, augmented random search uses perceptrons! There are fewer weights to adjust and learn, but at the same time, ARS manages to get higher rewards in specific applications!\n"
      ]
    },
    {
      "metadata": {
        "id": "Azjqd6JOVcy7"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import wrappers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzPOpcEyTLOs"
      },
      "cell_type": "markdown",
      "source": [
        "## *Here we declare a class to initialise hyper parameters involved in Bipedal*"
      ]
    },
    {
      "metadata": {
        "id": "gRtzFlKFVpAb"
      },
      "cell_type": "code",
      "source": [
        "class HP():\n",
        "    # Hyperparameters\n",
        "    def __init__(self,\n",
        "                 nb_steps=1000,\n",
        "                 episode_length=2000,\n",
        "                 learning_rate=0.02,\n",
        "                 num_deltas=16,\n",
        "                 num_best_deltas=16,\n",
        "                 noise=0.03,\n",
        "                 seed=1,\n",
        "                 env_name='BipedalWalker-v2',\n",
        "                 record_every=50):\n",
        "\n",
        "        self.nb_steps = nb_steps\n",
        "        self.episode_length = episode_length\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_deltas = num_deltas\n",
        "        self.num_best_deltas = num_best_deltas\n",
        "        assert self.num_best_deltas <= self.num_deltas\n",
        "        self.noise = noise\n",
        "        self.seed = seed\n",
        "        self.env_name = env_name\n",
        "        self.record_every = record_every"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__1HHlA3eTVy"
      },
      "cell_type": "markdown",
      "source": [
        "## Here we normalize the array of input and calculate the mean per observation and find out the difference in the mean"
      ]
    },
    {
      "metadata": {
        "id": "qcwrRlAlVpI8"
      },
      "cell_type": "code",
      "source": [
        "class Normalizer():\n",
        "    # Normalizes the inputs\n",
        "    def __init__(self, nb_inputs):\n",
        "        self.n = np.zeros(nb_inputs)\n",
        "        self.mean = np.zeros(nb_inputs)\n",
        "        self.mean_diff = np.zeros(nb_inputs)\n",
        "        self.var = np.zeros(nb_inputs)\n",
        "\n",
        "    def observe(self, x):\n",
        "        self.n += 1.0\n",
        "        last_mean = self.mean.copy()\n",
        "        self.mean += (x - self.mean) / self.n\n",
        "        self.mean_diff += (x - last_mean) * (x - self.mean)\n",
        "        self.var = (self.mean_diff / self.n).clip(min = 1e-2)\n",
        "\n",
        "    def normalize(self, inputs):\n",
        "        obs_mean = self.mean\n",
        "        obs_std = np.sqrt(self.var)\n",
        "        return (inputs - obs_mean) / obs_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fp4mvZGrpLmL"
      },
      "cell_type": "markdown",
      "source": [
        "## Pay attention to comments"
      ]
    },
    {
      "metadata": {
        "id": "SAakK-txVpQR"
      },
      "cell_type": "code",
      "source": [
        "class Policy():\n",
        "    def __init__(self, input_size, output_size, hp):\n",
        "      #this creates a zero matrix of rows,column\n",
        "        self.theta = np.zeros((output_size, input_size))\n",
        "        self.hp = hp\n",
        "\n",
        "    def evaluate(self, input, delta = None, direction = None):\n",
        "        if direction is None:\n",
        "          #.dot is numpy function for dot product\n",
        "            return self.theta.dot(input)\n",
        "        elif direction == \"+\":\n",
        "            return (self.theta + self.hp.noise * delta).dot(input)\n",
        "        elif direction == \"-\":\n",
        "            return (self.theta - self.hp.noise * delta).dot(input)\n",
        "\n",
        "    def sample_deltas(self):\n",
        "        return [np.random.randn(*self.theta.shape) for _ in range(self.hp.num_deltas)]\n",
        "#This code above here is super important\n",
        "#This is how the weights are updated according to which configuration of weights led to the biggest reward\n",
        "    def update(self, rollouts, sigma_rewards):\n",
        "        # sigma_rewards is the standard deviation of the rewards\n",
        "        step = np.zeros(self.theta.shape)\n",
        "        for r_pos, r_neg, delta in rollouts:\n",
        "            step += (r_pos - r_neg) * delta\n",
        "        self.theta += self.hp.learning_rate / (self.hp.num_best_deltas * sigma_rewards) * step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgzIRF71VxNm"
      },
      "cell_type": "code",
      "source": [
        "class ARSTrainer():\n",
        "    def __init__(self,\n",
        "                 hp=None,\n",
        "                 input_size=None,\n",
        "                 output_size=None,\n",
        "                 normalizer=None,\n",
        "                 policy=None,\n",
        "                 monitor_dir=None):\n",
        "\n",
        "        self.hp = hp or HP()\n",
        "        np.random.seed(self.hp.seed)\n",
        "        self.env = gym.make(self.hp.env_name)\n",
        "        if monitor_dir is not None:\n",
        "            should_record = lambda i: self.record_video\n",
        "            self.env = wrappers.Monitor(self.env, monitor_dir, video_callable=should_record, force=True)\n",
        "        self.hp.episode_length = self.env.spec.timestep_limit or self.hp.episode_length\n",
        "        self.input_size = input_size or self.env.observation_space.shape[0]\n",
        "        self.output_size = output_size or self.env.action_space.shape[0]\n",
        "        self.normalizer = normalizer or Normalizer(self.input_size)\n",
        "        self.policy = policy or Policy(self.input_size, self.output_size, self.hp)\n",
        "        self.record_video = False\n",
        "\n",
        "    # Explore the policy on one specific direction and over one episode\n",
        "    def explore(self, direction=None, delta=None):\n",
        "        state = self.env.reset()\n",
        "        done = False\n",
        "        num_plays = 0.0\n",
        "        sum_rewards = 0.0\n",
        "        while not done and num_plays < self.hp.episode_length:\n",
        "            self.normalizer.observe(state)\n",
        "            state = self.normalizer.normalize(state)\n",
        "            action = self.policy.evaluate(state, delta, direction)\n",
        "            state, reward, done, _ = self.env.step(action)\n",
        "            reward = max(min(reward, 1), -1)\n",
        "            sum_rewards += reward\n",
        "            num_plays += 1\n",
        "        return sum_rewards\n",
        "\n",
        "    def train(self):\n",
        "        for step in range(self.hp.nb_steps):\n",
        "            # initialize the random noise deltas and the positive/negative rewards\n",
        "            deltas = self.policy.sample_deltas()\n",
        "            positive_rewards = [0] * self.hp.num_deltas\n",
        "            negative_rewards = [0] * self.hp.num_deltas\n",
        "\n",
        "            # play an episode each with positive deltas and negative deltas, collect rewards\n",
        "            for k in range(self.hp.num_deltas):\n",
        "                positive_rewards[k] = self.explore(direction=\"+\", delta=deltas[k])\n",
        "                negative_rewards[k] = self.explore(direction=\"-\", delta=deltas[k])\n",
        "\n",
        "            # Compute the standard deviation of all rewards\n",
        "            sigma_rewards = np.array(positive_rewards + negative_rewards).std()\n",
        "\n",
        "            # Sort the rollouts by the max(r_pos, r_neg) and select the deltas with best rewards\n",
        "            scores = {k:max(r_pos, r_neg) for k,(r_pos,r_neg) in enumerate(zip(positive_rewards, negative_rewards))}\n",
        "            order = sorted(scores.keys(), key = lambda x:scores[x], reverse = True)[:self.hp.num_best_deltas]\n",
        "            rollouts = [(positive_rewards[k], negative_rewards[k], deltas[k]) for k in order]\n",
        "\n",
        "            # Update the policy\n",
        "            self.policy.update(rollouts, sigma_rewards)\n",
        "\n",
        "            # Only record video during evaluation, every n steps\n",
        "            if step % self.hp.record_every == 0:\n",
        "                self.record_video = True\n",
        "            # Play an episode with the new weights and print the score\n",
        "            reward_evaluation = self.explore()\n",
        "            print('Step: ', step, 'Reward: ', reward_evaluation)\n",
        "            self.record_video = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2aIv0lMV3_F"
      },
      "cell_type": "code",
      "source": [
        "def mkdir(base, name):\n",
        "    path = os.path.join(base, name)\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVuDOFFVV9xZ"
      },
      "cell_type": "code",
      "source": [
        "ENV_NAME = 'BipedalWalker-v2'\n",
        "\n",
        "videos_dir = mkdir('.', 'videos')\n",
        "monitor_dir = mkdir(videos_dir, ENV_NAME)\n",
        "\n",
        "hp = HP(env_name=ENV_NAME)\n",
        "trainer = ARSTrainer(hp=hp, monitor_dir=monitor_dir)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4C_waL3_lKXu"
      },
      "cell_type": "markdown",
      "source": [
        "# Download the episodes"
      ]
    },
    {
      "metadata": {
        "id": "5xvR-vXbBLB1"
      },
      "cell_type": "code",
      "source": [
        "!ls videos/{ENV_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYitauj1SePX"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "for file in glob.glob(\"videos/{}/openaigym.video.*.mp4\".format(ENV_NAME)):\n",
        "  files.download(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YnGL_Nxwjld0"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}